{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Develop MLPs for Time Series Forecasting\n",
    "\n",
    "Multilayer Perceptrons, or MLPs for short, can be applied to time series forecasting. A challenge with using MLPs for time series forecasting is in the preparation of the data. Specifically, lag observations must be flattened into feature vectors. \n",
    "\n",
    "In this tutorial, you will discover how to develop a suite of MLP models for a range of standard time series forecasting problems. The objective of this tutorial is to provide standalone examples of each model on each type of time series problem as a template that you can copy and adapt for your specific time series forecasting\n",
    "problem. \n",
    "\n",
    "We will discover how to develop a suite of Multilayer Perceptron models for a range of standard time series forecasting problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from numpy import hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a univariate sequence into samples\n",
    "def split_sequence(sequence, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the sequence\n",
    "        if end_ix > len(sequence)-1:\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(X), array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 180, 190]\n[10 20 30] 40\n[20 30 40] 50\n[30 40 50] 60\n[40 50 60] 70\n[50 60 70] 80\n[60 70 80] 90\n[70 80 90] 100\n[ 80  90 100] 110\n[ 90 100 110] 120\n[100 110 120] 130\n[110 120 130] 140\n[120 130 140] 150\n[130 140 150] 160\n[140 150 160] 170\n[150 160 170] 180\n[160 170 180] 190\n"
    }
   ],
   "source": [
    "# define input sequence\n",
    "raw_seq = [i*10 for i in range(1, 20)]\n",
    "print(raw_seq)\n",
    "\n",
    "# choose a number of time steps\n",
    "n_steps = 3\n",
    "\n",
    "# split into samples\n",
    "X, y = split_sequence(raw_seq, n_steps)\n",
    "\n",
    "# summarize the data\n",
    "for i in range(len(X)):\n",
    "    print(X[i], y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "# univariate mlp example\n",
    "from numpy import array\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:From C:\\Users\\Benedict\\Miniconda3\\envs\\kerasts\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\n"
    }
   ],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Dense(100, activation='relu', input_dim=n_steps))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:From C:\\Users\\Benedict\\Miniconda3\\envs\\kerasts\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.cast instead.\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<keras.callbacks.callbacks.History at 0x162b8985cc8>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# fit model\n",
    "model.fit(X, y, epochs=2000, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[140 150 160]]\n[[169.90907]]\n"
    }
   ],
   "source": [
    "# demonstrate prediction\n",
    "x_input = array([140, 150, 160])\n",
    "x_input = x_input.reshape((1, n_steps))\n",
    "print(x_input)\n",
    "yhat = model.predict(x_input)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate MLP Models\n",
    "\n",
    "Multivariate time series data means data where there is more than one observation for each time step. There are two main models that we may require with multivariate time series data\n",
    "\n",
    "### Multiple Input Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([ 25,  45,  65,  85, 105, 125, 145, 165, 185])"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "# define input sequence\n",
    "in_seq1 = array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
    "in_seq2 = array([15, 25, 35, 45, 55, 65, 75, 85, 95])\n",
    "out_seq = array([in_seq1[i] + in_seq2[i] for i in range(len(in_seq1))])\n",
    "out_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[ 10,  15,  25],\n       [ 20,  25,  45],\n       [ 30,  35,  65],\n       [ 40,  45,  85],\n       [ 50,  55, 105],\n       [ 60,  65, 125],\n       [ 70,  75, 145],\n       [ 80,  85, 165],\n       [ 90,  95, 185]])"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "# convert to [rows, columns] structure\n",
    "in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
    "in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n",
    "out_seq = out_seq.reshape((len(out_seq), 1))\n",
    "\n",
    "# horizontally stack columns\n",
    "dataset = hstack((in_seq1, in_seq2, out_seq))\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequences(sequences, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the dataset\n",
    "        if end_ix > len(sequences):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1, -1]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(X), array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(7, 3, 2) (7,)\n[[10 15]\n [20 25]\n [30 35]] 65\n[[20 25]\n [30 35]\n [40 45]] 85\n[[30 35]\n [40 45]\n [50 55]] 105\n[[40 45]\n [50 55]\n [60 65]] 125\n[[50 55]\n [60 65]\n [70 75]] 145\n[[60 65]\n [70 75]\n [80 85]] 165\n[[70 75]\n [80 85]\n [90 95]] 185\n"
    }
   ],
   "source": [
    "# choose a number of time steps\n",
    "n_steps = 3\n",
    "\n",
    "# convert into input/output\n",
    "X, y = split_sequences(dataset, n_steps)\n",
    "print(X.shape, y.shape)\n",
    "# Summarize the data\n",
    "for i in range(len(X)):\n",
    "    print(X[i], y[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Model\n",
    "Before we can fit an MLP on this data, we must flatten the shape of the input samples. MLPs require that the shape of the input portion of each sample is a vector. With a multivariate input, we will have multiple vectors, one for each time step. We can flatten the temporal structure of each input sample\n",
    "\n",
    "First, we can calculate the length of each input vector as the number of time steps multiplied\n",
    "by the number of features or time series. We can then use this vector size to reshape the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(7, 6)\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[10, 15, 20, 25, 30, 35],\n       [20, 25, 30, 35, 40, 45],\n       [30, 35, 40, 45, 50, 55],\n       [40, 45, 50, 55, 60, 65],\n       [50, 55, 60, 65, 70, 75],\n       [60, 65, 70, 75, 80, 85],\n       [70, 75, 80, 85, 90, 95]])"
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "# flatten input\n",
    "n_input = X.shape[1] * X.shape[2]\n",
    "X = X.reshape((X.shape[0], n_input))\n",
    "print(X.shape)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now define an MLP model for the multivariate input where the vector length is used\n",
    "for the input dimension argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Dense(100, activation='relu',input_dim=n_input))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<keras.callbacks.callbacks.History at 0x162bb739d08>"
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "# fit model\n",
    "model.fit(X, y, epochs=2000, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(1, 6) \n [[ 80  85  90  95 100 105]]\n[[205.39468]]\n"
    }
   ],
   "source": [
    "# Demonstrate prediction\n",
    "x_input = array([[80, 85], [90, 95], [100, 105]])\n",
    "x_input = x_input.reshape((1, n_input))\n",
    "print(x_input.shape, '\\n', x_input)\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('kerasts': conda)",
   "language": "python",
   "name": "python37764bitkerastscondab4e4928513be4f2f8a875af55b97eba7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}